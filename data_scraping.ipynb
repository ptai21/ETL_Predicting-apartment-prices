{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tìm hiểu về các công cụ Web scraping như:\n",
    "  + Beautiful soup: Khi áp dụng thì gặp nhiều vấn đề với trang Web mặc dù tốc độ nhanh nhưng lại không thu được thông tin gì\n",
    "  + Selenium: Khi crawl data thì tốn quá nhiều tài nguyên cũng như thời gian chạy( 20p/ 1 page dữ liệu)\n",
    "  + Scrapy: Tốc độ nhanh có thể coi là tools tốt nhất trong các loại và phù hợp với mục đích của nhóm là crawl toàn bộ dữ liệu trang web thông qua các Xpath\n",
    "- Các Vấn đề gặp phải khi crawling data:\n",
    "  + Thời gian thu thập dữ liệu khá mất nhiều thời gian => giải quyết bằng thư viện scrapy\n",
    "  + Độ chính xác khi cào dữ liệu:\n",
    "    * Thu thập chưa đúng với dữ liệu mà nhóm yêu cầu => giải quyết thay đổi các xpath chuẩn hơn dẫn tới dữ liệu cần thu thập đúng hơn\n",
    "    * Thu thập chưa đủ dữ liệu => giải quyết bằng cách là tăng độ trễ giữa các yêu cầu và thêm số lần thất bại sau mỗi lần thu thập"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 21:13:54 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: scrapybot)\n",
      "2024-06-06 21:13:54 [scrapy.utils.log] INFO: Versions: lxml 5.2.2.0, libxml2 2.12.6, cssselect 1.2.0, parsel 1.9.1, w3lib 2.1.2, Twisted 24.3.0, Python 3.12.0 (v3.12.0:0fb18b02c8, Oct  2 2023, 09:45:56) [Clang 13.0.0 (clang-1300.0.29.30)], pyOpenSSL 24.1.0 (OpenSSL 3.2.2 4 Jun 2024), cryptography 42.0.8, Platform macOS-14.4.1-arm64-arm-64bit\n",
      "2024-06-06 21:13:54 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2024-06-06 21:13:54 [py.warnings] WARNING: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2024-06-06 21:13:54 [scrapy.extensions.telnet] INFO: Telnet Password: 386ea9c9063d40a5\n",
      "2024-06-06 21:13:54 [py.warnings] WARNING: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scrapy/extensions/feedexport.py:406: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n",
      "2024-06-06 21:13:54 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2024-06-06 21:13:54 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'DOWNLOAD_DELAY': 2,\n",
      " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
      " 'LOG_LEVEL': 'INFO',\n",
      " 'RETRY_TIMES': 3}\n",
      "2024-06-06 21:13:54 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2024-06-06 21:13:54 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2024-06-06 21:13:54 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2024-06-06 21:13:54 [scrapy.core.engine] INFO: Spider opened\n",
      "2024-06-06 21:13:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2024-06-06 21:13:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2024-06-06 21:14:54 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 26 pages/min), scraped 9 items (at 9 items/min)\n",
      "2024-06-06 21:15:54 [scrapy.extensions.logstats] INFO: Crawled 50 pages (at 24 pages/min), scraped 33 items (at 24 items/min)\n",
      "2024-06-06 21:16:54 [scrapy.extensions.logstats] INFO: Crawled 75 pages (at 25 pages/min), scraped 58 items (at 25 items/min)\n",
      "2024-06-06 21:17:54 [scrapy.extensions.logstats] INFO: Crawled 100 pages (at 25 pages/min), scraped 83 items (at 25 items/min)\n",
      "2024-06-06 21:18:54 [scrapy.extensions.logstats] INFO: Crawled 125 pages (at 25 pages/min), scraped 108 items (at 25 items/min)\n",
      "2024-06-06 21:19:54 [scrapy.extensions.logstats] INFO: Crawled 150 pages (at 25 pages/min), scraped 133 items (at 25 items/min)\n",
      "2024-06-06 21:20:54 [scrapy.extensions.logstats] INFO: Crawled 174 pages (at 24 pages/min), scraped 157 items (at 24 items/min)\n",
      "2024-06-06 21:21:54 [scrapy.extensions.logstats] INFO: Crawled 197 pages (at 23 pages/min), scraped 180 items (at 23 items/min)\n",
      "2024-06-06 21:22:54 [scrapy.extensions.logstats] INFO: Crawled 222 pages (at 25 pages/min), scraped 205 items (at 25 items/min)\n",
      "2024-06-06 21:23:54 [scrapy.extensions.logstats] INFO: Crawled 245 pages (at 23 pages/min), scraped 228 items (at 23 items/min)\n",
      "2024-06-06 21:24:54 [scrapy.extensions.logstats] INFO: Crawled 267 pages (at 22 pages/min), scraped 250 items (at 22 items/min)\n",
      "2024-06-06 21:25:54 [scrapy.extensions.logstats] INFO: Crawled 291 pages (at 24 pages/min), scraped 274 items (at 24 items/min)\n",
      "2024-06-06 21:26:54 [scrapy.extensions.logstats] INFO: Crawled 314 pages (at 23 pages/min), scraped 297 items (at 23 items/min)\n",
      "2024-06-06 21:27:54 [scrapy.extensions.logstats] INFO: Crawled 340 pages (at 26 pages/min), scraped 323 items (at 26 items/min)\n",
      "2024-06-06 21:28:54 [scrapy.extensions.logstats] INFO: Crawled 365 pages (at 25 pages/min), scraped 340 items (at 17 items/min)\n",
      "2024-06-06 21:29:54 [scrapy.extensions.logstats] INFO: Crawled 391 pages (at 26 pages/min), scraped 357 items (at 17 items/min)\n",
      "2024-06-06 21:30:54 [scrapy.extensions.logstats] INFO: Crawled 416 pages (at 25 pages/min), scraped 382 items (at 25 items/min)\n",
      "2024-06-06 21:31:54 [scrapy.extensions.logstats] INFO: Crawled 441 pages (at 25 pages/min), scraped 407 items (at 25 items/min)\n",
      "2024-06-06 21:32:54 [scrapy.extensions.logstats] INFO: Crawled 466 pages (at 25 pages/min), scraped 432 items (at 25 items/min)\n",
      "2024-06-06 21:33:54 [scrapy.extensions.logstats] INFO: Crawled 489 pages (at 23 pages/min), scraped 455 items (at 23 items/min)\n",
      "2024-06-06 21:34:54 [scrapy.extensions.logstats] INFO: Crawled 513 pages (at 24 pages/min), scraped 478 items (at 23 items/min)\n",
      "2024-06-06 21:35:54 [scrapy.extensions.logstats] INFO: Crawled 537 pages (at 24 pages/min), scraped 503 items (at 25 items/min)\n",
      "2024-06-06 21:36:54 [scrapy.extensions.logstats] INFO: Crawled 561 pages (at 24 pages/min), scraped 527 items (at 24 items/min)\n",
      "2024-06-06 21:37:54 [scrapy.extensions.logstats] INFO: Crawled 585 pages (at 24 pages/min), scraped 551 items (at 24 items/min)\n",
      "2024-06-06 21:38:54 [scrapy.extensions.logstats] INFO: Crawled 602 pages (at 17 pages/min), scraped 568 items (at 17 items/min)\n",
      "2024-06-06 21:39:54 [scrapy.extensions.logstats] INFO: Crawled 626 pages (at 24 pages/min), scraped 592 items (at 24 items/min)\n",
      "2024-06-06 21:40:54 [scrapy.extensions.logstats] INFO: Crawled 648 pages (at 22 pages/min), scraped 614 items (at 22 items/min)\n",
      "2024-06-06 21:41:54 [scrapy.extensions.logstats] INFO: Crawled 671 pages (at 23 pages/min), scraped 637 items (at 23 items/min)\n",
      "2024-06-06 21:42:54 [scrapy.extensions.logstats] INFO: Crawled 700 pages (at 29 pages/min), scraped 665 items (at 28 items/min)\n",
      "2024-06-06 21:43:54 [scrapy.extensions.logstats] INFO: Crawled 726 pages (at 26 pages/min), scraped 680 items (at 15 items/min)\n",
      "2024-06-06 21:44:54 [scrapy.extensions.logstats] INFO: Crawled 750 pages (at 24 pages/min), scraped 699 items (at 19 items/min)\n",
      "2024-06-06 21:45:54 [scrapy.extensions.logstats] INFO: Crawled 776 pages (at 26 pages/min), scraped 725 items (at 26 items/min)\n",
      "2024-06-06 21:46:54 [scrapy.extensions.logstats] INFO: Crawled 801 pages (at 25 pages/min), scraped 750 items (at 25 items/min)\n",
      "2024-06-06 21:47:54 [scrapy.extensions.logstats] INFO: Crawled 825 pages (at 24 pages/min), scraped 774 items (at 24 items/min)\n",
      "2024-06-06 21:48:54 [scrapy.extensions.logstats] INFO: Crawled 851 pages (at 26 pages/min), scraped 800 items (at 26 items/min)\n",
      "2024-06-06 21:49:54 [scrapy.extensions.logstats] INFO: Crawled 873 pages (at 22 pages/min), scraped 822 items (at 22 items/min)\n",
      "2024-06-06 21:50:54 [scrapy.extensions.logstats] INFO: Crawled 898 pages (at 25 pages/min), scraped 847 items (at 25 items/min)\n",
      "2024-06-06 21:51:54 [scrapy.extensions.logstats] INFO: Crawled 922 pages (at 24 pages/min), scraped 871 items (at 24 items/min)\n",
      "2024-06-06 21:52:54 [scrapy.extensions.logstats] INFO: Crawled 946 pages (at 24 pages/min), scraped 895 items (at 24 items/min)\n",
      "2024-06-06 21:53:54 [scrapy.extensions.logstats] INFO: Crawled 970 pages (at 24 pages/min), scraped 919 items (at 24 items/min)\n",
      "2024-06-06 21:54:54 [scrapy.extensions.logstats] INFO: Crawled 994 pages (at 24 pages/min), scraped 943 items (at 24 items/min)\n",
      "2024-06-06 21:55:54 [scrapy.extensions.logstats] INFO: Crawled 1017 pages (at 23 pages/min), scraped 966 items (at 23 items/min)\n",
      "2024-06-06 21:56:54 [scrapy.extensions.logstats] INFO: Crawled 1042 pages (at 25 pages/min), scraped 991 items (at 25 items/min)\n",
      "2024-06-06 21:57:54 [scrapy.extensions.logstats] INFO: Crawled 1067 pages (at 25 pages/min), scraped 1016 items (at 25 items/min)\n",
      "2024-06-06 21:58:54 [scrapy.extensions.logstats] INFO: Crawled 1092 pages (at 25 pages/min), scraped 1024 items (at 8 items/min)\n",
      "2024-06-06 21:59:54 [scrapy.extensions.logstats] INFO: Crawled 1116 pages (at 24 pages/min), scraped 1048 items (at 24 items/min)\n",
      "2024-06-06 22:00:54 [scrapy.extensions.logstats] INFO: Crawled 1141 pages (at 25 pages/min), scraped 1073 items (at 25 items/min)\n",
      "2024-06-06 22:01:54 [scrapy.extensions.logstats] INFO: Crawled 1165 pages (at 24 pages/min), scraped 1097 items (at 24 items/min)\n",
      "2024-06-06 22:02:54 [scrapy.extensions.logstats] INFO: Crawled 1189 pages (at 24 pages/min), scraped 1121 items (at 24 items/min)\n",
      "2024-06-06 22:03:54 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 24 pages/min), scraped 1145 items (at 24 items/min)\n",
      "2024-06-06 22:04:54 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 20 pages/min), scraped 1165 items (at 20 items/min)\n",
      "2024-06-06 22:05:54 [scrapy.extensions.logstats] INFO: Crawled 1262 pages (at 29 pages/min), scraped 1194 items (at 29 items/min)\n",
      "2024-06-06 22:06:54 [scrapy.extensions.logstats] INFO: Crawled 1287 pages (at 25 pages/min), scraped 1219 items (at 25 items/min)\n",
      "2024-06-06 22:07:54 [scrapy.extensions.logstats] INFO: Crawled 1305 pages (at 18 pages/min), scraped 1237 items (at 18 items/min)\n",
      "2024-06-06 22:08:54 [scrapy.extensions.logstats] INFO: Crawled 1333 pages (at 28 pages/min), scraped 1265 items (at 28 items/min)\n",
      "2024-06-06 22:09:54 [scrapy.extensions.logstats] INFO: Crawled 1362 pages (at 29 pages/min), scraped 1294 items (at 29 items/min)\n",
      "2024-06-06 22:10:54 [scrapy.extensions.logstats] INFO: Crawled 1386 pages (at 24 pages/min), scraped 1318 items (at 24 items/min)\n",
      "2024-06-06 22:11:54 [scrapy.extensions.logstats] INFO: Crawled 1411 pages (at 25 pages/min), scraped 1343 items (at 25 items/min)\n",
      "2024-06-06 22:12:54 [scrapy.extensions.logstats] INFO: Crawled 1435 pages (at 24 pages/min), scraped 1360 items (at 17 items/min)\n",
      "2024-06-06 22:13:54 [scrapy.extensions.logstats] INFO: Crawled 1459 pages (at 24 pages/min), scraped 1374 items (at 14 items/min)\n",
      "2024-06-06 22:14:54 [scrapy.extensions.logstats] INFO: Crawled 1483 pages (at 24 pages/min), scraped 1398 items (at 24 items/min)\n",
      "2024-06-06 22:15:54 [scrapy.extensions.logstats] INFO: Crawled 1507 pages (at 24 pages/min), scraped 1422 items (at 24 items/min)\n",
      "2024-06-06 22:16:54 [scrapy.extensions.logstats] INFO: Crawled 1530 pages (at 23 pages/min), scraped 1445 items (at 23 items/min)\n",
      "2024-06-06 22:17:54 [scrapy.extensions.logstats] INFO: Crawled 1549 pages (at 19 pages/min), scraped 1464 items (at 19 items/min)\n",
      "2024-06-06 22:18:54 [scrapy.extensions.logstats] INFO: Crawled 1573 pages (at 24 pages/min), scraped 1488 items (at 24 items/min)\n",
      "2024-06-06 22:19:54 [scrapy.extensions.logstats] INFO: Crawled 1597 pages (at 24 pages/min), scraped 1512 items (at 24 items/min)\n",
      "2024-06-06 22:20:54 [scrapy.extensions.logstats] INFO: Crawled 1621 pages (at 24 pages/min), scraped 1536 items (at 24 items/min)\n",
      "2024-06-06 22:21:54 [scrapy.extensions.logstats] INFO: Crawled 1647 pages (at 26 pages/min), scraped 1562 items (at 26 items/min)\n",
      "2024-06-06 22:22:54 [scrapy.extensions.logstats] INFO: Crawled 1676 pages (at 29 pages/min), scraped 1591 items (at 29 items/min)\n",
      "2024-06-06 22:23:54 [scrapy.extensions.logstats] INFO: Crawled 1693 pages (at 17 pages/min), scraped 1608 items (at 17 items/min)\n",
      "2024-06-06 22:24:54 [scrapy.extensions.logstats] INFO: Crawled 1707 pages (at 14 pages/min), scraped 1622 items (at 14 items/min)\n",
      "2024-06-06 22:25:54 [scrapy.extensions.logstats] INFO: Crawled 1730 pages (at 23 pages/min), scraped 1645 items (at 23 items/min)\n",
      "2024-06-06 22:26:54 [scrapy.extensions.logstats] INFO: Crawled 1757 pages (at 27 pages/min), scraped 1672 items (at 27 items/min)\n",
      "2024-06-06 22:27:54 [scrapy.extensions.logstats] INFO: Crawled 1784 pages (at 27 pages/min), scraped 1699 items (at 27 items/min)\n",
      "2024-06-06 22:28:54 [scrapy.extensions.logstats] INFO: Crawled 1807 pages (at 23 pages/min), scraped 1704 items (at 5 items/min)\n",
      "2024-06-06 22:29:54 [scrapy.extensions.logstats] INFO: Crawled 1829 pages (at 22 pages/min), scraped 1727 items (at 23 items/min)\n",
      "2024-06-06 22:30:54 [scrapy.extensions.logstats] INFO: Crawled 1852 pages (at 23 pages/min), scraped 1750 items (at 23 items/min)\n",
      "2024-06-06 22:31:54 [scrapy.extensions.logstats] INFO: Crawled 1875 pages (at 23 pages/min), scraped 1773 items (at 23 items/min)\n",
      "2024-06-06 22:32:54 [scrapy.extensions.logstats] INFO: Crawled 1897 pages (at 22 pages/min), scraped 1795 items (at 22 items/min)\n",
      "2024-06-06 22:33:54 [scrapy.extensions.logstats] INFO: Crawled 1917 pages (at 20 pages/min), scraped 1815 items (at 20 items/min)\n",
      "2024-06-06 22:34:54 [scrapy.extensions.logstats] INFO: Crawled 1938 pages (at 21 pages/min), scraped 1836 items (at 21 items/min)\n",
      "2024-06-06 22:35:54 [scrapy.extensions.logstats] INFO: Crawled 1955 pages (at 17 pages/min), scraped 1853 items (at 17 items/min)\n",
      "2024-06-06 22:36:54 [scrapy.extensions.logstats] INFO: Crawled 1974 pages (at 19 pages/min), scraped 1872 items (at 19 items/min)\n",
      "2024-06-06 22:37:54 [scrapy.extensions.logstats] INFO: Crawled 1997 pages (at 23 pages/min), scraped 1895 items (at 23 items/min)\n",
      "2024-06-06 22:38:54 [scrapy.extensions.logstats] INFO: Crawled 2025 pages (at 28 pages/min), scraped 1923 items (at 28 items/min)\n",
      "2024-06-06 22:39:54 [scrapy.extensions.logstats] INFO: Crawled 2055 pages (at 30 pages/min), scraped 1953 items (at 30 items/min)\n",
      "2024-06-06 22:40:54 [scrapy.extensions.logstats] INFO: Crawled 2079 pages (at 24 pages/min), scraped 1977 items (at 24 items/min)\n",
      "2024-06-06 22:41:54 [scrapy.extensions.logstats] INFO: Crawled 2104 pages (at 25 pages/min), scraped 2002 items (at 25 items/min)\n",
      "2024-06-06 22:42:54 [scrapy.extensions.logstats] INFO: Crawled 2127 pages (at 23 pages/min), scraped 2025 items (at 23 items/min)\n",
      "2024-06-06 22:43:54 [scrapy.extensions.logstats] INFO: Crawled 2150 pages (at 23 pages/min), scraped 2040 items (at 15 items/min)\n",
      "2024-06-06 22:44:54 [scrapy.extensions.logstats] INFO: Crawled 2174 pages (at 24 pages/min), scraped 2055 items (at 15 items/min)\n",
      "2024-06-06 22:45:54 [scrapy.extensions.logstats] INFO: Crawled 2199 pages (at 25 pages/min), scraped 2079 items (at 24 items/min)\n",
      "2024-06-06 22:46:54 [scrapy.extensions.logstats] INFO: Crawled 2222 pages (at 23 pages/min), scraped 2103 items (at 24 items/min)\n",
      "2024-06-06 22:47:54 [scrapy.extensions.logstats] INFO: Crawled 2246 pages (at 24 pages/min), scraped 2127 items (at 24 items/min)\n",
      "2024-06-06 22:48:54 [scrapy.extensions.logstats] INFO: Crawled 2271 pages (at 25 pages/min), scraped 2152 items (at 25 items/min)\n",
      "2024-06-06 22:49:54 [scrapy.extensions.logstats] INFO: Crawled 2296 pages (at 25 pages/min), scraped 2177 items (at 25 items/min)\n",
      "2024-06-06 22:50:54 [scrapy.extensions.logstats] INFO: Crawled 2321 pages (at 25 pages/min), scraped 2202 items (at 25 items/min)\n",
      "2024-06-06 22:51:54 [scrapy.extensions.logstats] INFO: Crawled 2346 pages (at 25 pages/min), scraped 2227 items (at 25 items/min)\n",
      "2024-06-06 22:52:54 [scrapy.extensions.logstats] INFO: Crawled 2369 pages (at 23 pages/min), scraped 2250 items (at 23 items/min)\n",
      "2024-06-06 22:53:54 [scrapy.extensions.logstats] INFO: Crawled 2394 pages (at 25 pages/min), scraped 2275 items (at 25 items/min)\n",
      "2024-06-06 22:54:54 [scrapy.extensions.logstats] INFO: Crawled 2419 pages (at 25 pages/min), scraped 2300 items (at 25 items/min)\n",
      "2024-06-06 22:55:54 [scrapy.extensions.logstats] INFO: Crawled 2443 pages (at 24 pages/min), scraped 2324 items (at 24 items/min)\n",
      "2024-06-06 22:56:54 [scrapy.extensions.logstats] INFO: Crawled 2467 pages (at 24 pages/min), scraped 2348 items (at 24 items/min)\n",
      "2024-06-06 22:57:54 [scrapy.extensions.logstats] INFO: Crawled 2492 pages (at 25 pages/min), scraped 2373 items (at 25 items/min)\n",
      "2024-06-06 22:58:54 [scrapy.extensions.logstats] INFO: Crawled 2516 pages (at 24 pages/min), scraped 2381 items (at 8 items/min)\n",
      "2024-06-06 22:59:54 [scrapy.extensions.logstats] INFO: Crawled 2540 pages (at 24 pages/min), scraped 2405 items (at 24 items/min)\n",
      "2024-06-06 23:00:54 [scrapy.extensions.logstats] INFO: Crawled 2564 pages (at 24 pages/min), scraped 2429 items (at 24 items/min)\n",
      "2024-06-06 23:01:54 [scrapy.extensions.logstats] INFO: Crawled 2590 pages (at 26 pages/min), scraped 2455 items (at 26 items/min)\n",
      "2024-06-06 23:02:54 [scrapy.extensions.logstats] INFO: Crawled 2613 pages (at 23 pages/min), scraped 2478 items (at 23 items/min)\n",
      "2024-06-06 23:03:54 [scrapy.extensions.logstats] INFO: Crawled 2638 pages (at 25 pages/min), scraped 2503 items (at 25 items/min)\n",
      "2024-06-06 23:04:54 [scrapy.extensions.logstats] INFO: Crawled 2661 pages (at 23 pages/min), scraped 2526 items (at 23 items/min)\n",
      "2024-06-06 23:05:54 [scrapy.extensions.logstats] INFO: Crawled 2685 pages (at 24 pages/min), scraped 2550 items (at 24 items/min)\n",
      "2024-06-06 23:06:54 [scrapy.extensions.logstats] INFO: Crawled 2709 pages (at 24 pages/min), scraped 2574 items (at 24 items/min)\n",
      "2024-06-06 23:07:54 [scrapy.extensions.logstats] INFO: Crawled 2735 pages (at 26 pages/min), scraped 2599 items (at 25 items/min)\n",
      "2024-06-06 23:08:54 [scrapy.extensions.logstats] INFO: Crawled 2760 pages (at 25 pages/min), scraped 2625 items (at 26 items/min)\n",
      "2024-06-06 23:09:54 [scrapy.extensions.logstats] INFO: Crawled 2786 pages (at 26 pages/min), scraped 2651 items (at 26 items/min)\n",
      "2024-06-06 23:10:54 [scrapy.extensions.logstats] INFO: Crawled 2810 pages (at 24 pages/min), scraped 2675 items (at 24 items/min)\n",
      "2024-06-06 23:11:54 [scrapy.extensions.logstats] INFO: Crawled 2837 pages (at 27 pages/min), scraped 2700 items (at 25 items/min)\n",
      "2024-06-06 23:12:54 [scrapy.extensions.logstats] INFO: Crawled 2861 pages (at 24 pages/min), scraped 2709 items (at 9 items/min)\n",
      "2024-06-06 23:13:54 [scrapy.extensions.logstats] INFO: Crawled 2885 pages (at 24 pages/min), scraped 2733 items (at 24 items/min)\n",
      "2024-06-06 23:14:54 [scrapy.extensions.logstats] INFO: Crawled 2908 pages (at 23 pages/min), scraped 2756 items (at 23 items/min)\n",
      "2024-06-06 23:15:54 [scrapy.extensions.logstats] INFO: Crawled 2933 pages (at 25 pages/min), scraped 2781 items (at 25 items/min)\n",
      "2024-06-06 23:16:54 [scrapy.extensions.logstats] INFO: Crawled 2957 pages (at 24 pages/min), scraped 2804 items (at 23 items/min)\n",
      "2024-06-06 23:17:54 [scrapy.extensions.logstats] INFO: Crawled 2980 pages (at 23 pages/min), scraped 2828 items (at 24 items/min)\n",
      "2024-06-06 23:18:54 [scrapy.extensions.logstats] INFO: Crawled 3003 pages (at 23 pages/min), scraped 2851 items (at 23 items/min)\n",
      "2024-06-06 23:19:54 [scrapy.extensions.logstats] INFO: Crawled 3028 pages (at 25 pages/min), scraped 2876 items (at 25 items/min)\n",
      "2024-06-06 23:20:54 [scrapy.extensions.logstats] INFO: Crawled 3054 pages (at 26 pages/min), scraped 2902 items (at 26 items/min)\n",
      "2024-06-06 23:21:54 [scrapy.extensions.logstats] INFO: Crawled 3078 pages (at 24 pages/min), scraped 2926 items (at 24 items/min)\n",
      "2024-06-06 23:22:54 [scrapy.extensions.logstats] INFO: Crawled 3101 pages (at 23 pages/min), scraped 2949 items (at 23 items/min)\n",
      "2024-06-06 23:23:54 [scrapy.extensions.logstats] INFO: Crawled 3126 pages (at 25 pages/min), scraped 2974 items (at 25 items/min)\n",
      "2024-06-06 23:24:54 [scrapy.extensions.logstats] INFO: Crawled 3149 pages (at 23 pages/min), scraped 2997 items (at 23 items/min)\n",
      "2024-06-06 23:25:54 [scrapy.extensions.logstats] INFO: Crawled 3173 pages (at 24 pages/min), scraped 3021 items (at 24 items/min)\n",
      "2024-06-06 23:26:54 [scrapy.extensions.logstats] INFO: Crawled 3198 pages (at 25 pages/min), scraped 3040 items (at 19 items/min)\n",
      "2024-06-06 23:27:54 [scrapy.extensions.logstats] INFO: Crawled 3221 pages (at 23 pages/min), scraped 3052 items (at 12 items/min)\n",
      "2024-06-06 23:28:54 [scrapy.extensions.logstats] INFO: Crawled 3245 pages (at 24 pages/min), scraped 3076 items (at 24 items/min)\n",
      "2024-06-06 23:29:54 [scrapy.extensions.logstats] INFO: Crawled 3270 pages (at 25 pages/min), scraped 3101 items (at 25 items/min)\n",
      "2024-06-06 23:30:54 [scrapy.extensions.logstats] INFO: Crawled 3293 pages (at 23 pages/min), scraped 3123 items (at 22 items/min)\n",
      "2024-06-06 23:31:54 [scrapy.extensions.logstats] INFO: Crawled 3316 pages (at 23 pages/min), scraped 3147 items (at 24 items/min)\n",
      "2024-06-06 23:32:54 [scrapy.extensions.logstats] INFO: Crawled 3340 pages (at 24 pages/min), scraped 3171 items (at 24 items/min)\n",
      "2024-06-06 23:33:54 [scrapy.extensions.logstats] INFO: Crawled 3364 pages (at 24 pages/min), scraped 3195 items (at 24 items/min)\n",
      "2024-06-06 23:34:54 [scrapy.extensions.logstats] INFO: Crawled 3389 pages (at 25 pages/min), scraped 3219 items (at 24 items/min)\n",
      "2024-06-06 23:35:54 [scrapy.extensions.logstats] INFO: Crawled 3413 pages (at 24 pages/min), scraped 3244 items (at 25 items/min)\n",
      "2024-06-06 23:36:54 [scrapy.extensions.logstats] INFO: Crawled 3438 pages (at 25 pages/min), scraped 3269 items (at 25 items/min)\n",
      "2024-06-06 23:37:54 [scrapy.extensions.logstats] INFO: Crawled 3462 pages (at 24 pages/min), scraped 3293 items (at 24 items/min)\n",
      "2024-06-06 23:38:54 [scrapy.extensions.logstats] INFO: Crawled 3488 pages (at 26 pages/min), scraped 3318 items (at 25 items/min)\n",
      "2024-06-06 23:39:54 [scrapy.extensions.logstats] INFO: Crawled 3511 pages (at 23 pages/min), scraped 3342 items (at 24 items/min)\n",
      "2024-06-06 23:40:54 [scrapy.extensions.logstats] INFO: Crawled 3537 pages (at 26 pages/min), scraped 3368 items (at 26 items/min)\n",
      "2024-06-06 23:41:54 [scrapy.extensions.logstats] INFO: Crawled 3561 pages (at 24 pages/min), scraped 3380 items (at 12 items/min)\n",
      "2024-06-06 23:42:54 [scrapy.extensions.logstats] INFO: Crawled 3585 pages (at 24 pages/min), scraped 3399 items (at 19 items/min)\n",
      "2024-06-06 23:43:54 [scrapy.extensions.logstats] INFO: Crawled 3611 pages (at 26 pages/min), scraped 3425 items (at 26 items/min)\n",
      "2024-06-06 23:44:54 [scrapy.extensions.logstats] INFO: Crawled 3634 pages (at 23 pages/min), scraped 3448 items (at 23 items/min)\n",
      "2024-06-06 23:45:54 [scrapy.extensions.logstats] INFO: Crawled 3657 pages (at 23 pages/min), scraped 3471 items (at 23 items/min)\n",
      "2024-06-06 23:46:54 [scrapy.extensions.logstats] INFO: Crawled 3681 pages (at 24 pages/min), scraped 3495 items (at 24 items/min)\n",
      "2024-06-06 23:47:54 [scrapy.extensions.logstats] INFO: Crawled 3706 pages (at 25 pages/min), scraped 3520 items (at 25 items/min)\n",
      "2024-06-06 23:48:54 [scrapy.extensions.logstats] INFO: Crawled 3731 pages (at 25 pages/min), scraped 3545 items (at 25 items/min)\n",
      "2024-06-06 23:49:54 [scrapy.extensions.logstats] INFO: Crawled 3758 pages (at 27 pages/min), scraped 3572 items (at 27 items/min)\n",
      "2024-06-06 23:50:54 [scrapy.extensions.logstats] INFO: Crawled 3785 pages (at 27 pages/min), scraped 3599 items (at 27 items/min)\n",
      "2024-06-06 23:51:54 [scrapy.extensions.logstats] INFO: Crawled 3809 pages (at 24 pages/min), scraped 3623 items (at 24 items/min)\n",
      "2024-06-06 23:52:54 [scrapy.extensions.logstats] INFO: Crawled 3833 pages (at 24 pages/min), scraped 3646 items (at 23 items/min)\n",
      "2024-06-06 23:53:54 [scrapy.extensions.logstats] INFO: Crawled 3857 pages (at 24 pages/min), scraped 3671 items (at 25 items/min)\n",
      "2024-06-06 23:54:54 [scrapy.extensions.logstats] INFO: Crawled 3881 pages (at 24 pages/min), scraped 3695 items (at 24 items/min)\n",
      "2024-06-06 23:55:54 [scrapy.extensions.logstats] INFO: Crawled 3903 pages (at 22 pages/min), scraped 3717 items (at 22 items/min)\n",
      "2024-06-06 23:56:54 [scrapy.extensions.logstats] INFO: Crawled 3928 pages (at 25 pages/min), scraped 3725 items (at 8 items/min)\n",
      "2024-06-06 23:57:54 [scrapy.extensions.logstats] INFO: Crawled 3952 pages (at 24 pages/min), scraped 3749 items (at 24 items/min)\n",
      "2024-06-06 23:58:54 [scrapy.extensions.logstats] INFO: Crawled 3977 pages (at 25 pages/min), scraped 3774 items (at 25 items/min)\n",
      "2024-06-06 23:59:54 [scrapy.extensions.logstats] INFO: Crawled 4004 pages (at 27 pages/min), scraped 3801 items (at 27 items/min)\n",
      "2024-06-07 00:00:54 [scrapy.extensions.logstats] INFO: Crawled 4027 pages (at 23 pages/min), scraped 3824 items (at 23 items/min)\n",
      "2024-06-07 00:01:54 [scrapy.extensions.logstats] INFO: Crawled 4052 pages (at 25 pages/min), scraped 3849 items (at 25 items/min)\n",
      "2024-06-07 00:02:54 [scrapy.extensions.logstats] INFO: Crawled 4075 pages (at 23 pages/min), scraped 3872 items (at 23 items/min)\n",
      "2024-06-07 00:03:54 [scrapy.extensions.logstats] INFO: Crawled 4099 pages (at 24 pages/min), scraped 3896 items (at 24 items/min)\n",
      "2024-06-07 00:04:54 [scrapy.extensions.logstats] INFO: Crawled 4124 pages (at 25 pages/min), scraped 3921 items (at 25 items/min)\n",
      "2024-06-07 00:05:54 [scrapy.extensions.logstats] INFO: Crawled 4148 pages (at 24 pages/min), scraped 3945 items (at 24 items/min)\n",
      "2024-06-07 00:06:54 [scrapy.extensions.logstats] INFO: Crawled 4169 pages (at 21 pages/min), scraped 3966 items (at 21 items/min)\n",
      "2024-06-07 00:07:54 [scrapy.extensions.logstats] INFO: Crawled 4194 pages (at 25 pages/min), scraped 3991 items (at 25 items/min)\n",
      "2024-06-07 00:08:54 [scrapy.extensions.logstats] INFO: Crawled 4220 pages (at 26 pages/min), scraped 4017 items (at 26 items/min)\n",
      "2024-06-07 00:09:54 [scrapy.extensions.logstats] INFO: Crawled 4245 pages (at 25 pages/min), scraped 4042 items (at 25 items/min)\n",
      "2024-06-07 00:10:54 [scrapy.extensions.logstats] INFO: Crawled 4271 pages (at 26 pages/min), scraped 4060 items (at 18 items/min)\n",
      "2024-06-07 00:11:54 [scrapy.extensions.logstats] INFO: Crawled 4295 pages (at 24 pages/min), scraped 4081 items (at 21 items/min)\n",
      "2024-06-07 00:12:54 [scrapy.extensions.logstats] INFO: Crawled 4319 pages (at 24 pages/min), scraped 4105 items (at 24 items/min)\n",
      "2024-06-07 00:13:54 [scrapy.extensions.logstats] INFO: Crawled 4344 pages (at 25 pages/min), scraped 4130 items (at 25 items/min)\n",
      "2024-06-07 00:14:54 [scrapy.extensions.logstats] INFO: Crawled 4369 pages (at 25 pages/min), scraped 4155 items (at 25 items/min)\n",
      "2024-06-07 00:15:54 [scrapy.extensions.logstats] INFO: Crawled 4393 pages (at 24 pages/min), scraped 4179 items (at 24 items/min)\n",
      "2024-06-07 00:16:54 [scrapy.extensions.logstats] INFO: Crawled 4416 pages (at 23 pages/min), scraped 4202 items (at 23 items/min)\n",
      "2024-06-07 00:17:54 [scrapy.extensions.logstats] INFO: Crawled 4440 pages (at 24 pages/min), scraped 4226 items (at 24 items/min)\n",
      "2024-06-07 00:18:54 [scrapy.extensions.logstats] INFO: Crawled 4464 pages (at 24 pages/min), scraped 4250 items (at 24 items/min)\n",
      "2024-06-07 00:19:29 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2024-06-07 00:19:29 [scrapy.extensions.feedexport] INFO: Stored json feed (4264 items) in: real_estate_data2.json\n",
      "2024-06-07 00:19:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 1552858,\n",
      " 'downloader/request_count': 4520,\n",
      " 'downloader/request_method_count/GET': 4520,\n",
      " 'downloader/response_bytes': 71391460,\n",
      " 'downloader/response_count': 4520,\n",
      " 'downloader/response_status_count/200': 4478,\n",
      " 'downloader/response_status_count/302': 42,\n",
      " 'elapsed_time_seconds': 11134.768528,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2024, 6, 6, 17, 19, 29, 506290, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 505592205,\n",
      " 'httpcompression/response_count': 4478,\n",
      " 'item_scraped_count': 4264,\n",
      " 'log_count/INFO': 196,\n",
      " 'log_count/WARNING': 2,\n",
      " 'memusage/max': 154238976,\n",
      " 'memusage/startup': 103989248,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 4478,\n",
      " 'scheduler/dequeued': 4520,\n",
      " 'scheduler/dequeued/memory': 4520,\n",
      " 'scheduler/enqueued': 4520,\n",
      " 'scheduler/enqueued/memory': 4520,\n",
      " 'start_time': datetime.datetime(2024, 6, 6, 14, 13, 54, 737762, tzinfo=datetime.timezone.utc)}\n",
      "2024-06-07 00:19:29 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.http import Request\n",
    "\n",
    "class RealEstateSpider(scrapy.Spider):\n",
    "    \n",
    "    name = \"realestate\"\n",
    "    allowed_domains = [\"batdongsan.vn\"]\n",
    "    start_urls = [f\"https://batdongsan.vn/ban-can-ho-chung-cu/p{i}\" for i in range(1, 215)]\n",
    "\n",
    "    custom_settings = {\n",
    "        'FEED_FORMAT': 'json',\n",
    "        'FEED_URI': 'real_estate_data2.json',\n",
    "        'FEED_EXPORT_ENCODING': 'utf-8',\n",
    "        'DOWNLOAD_DELAY': 2,  # Thêm độ trễ giữa các yêu cầu\n",
    "        'RETRY_TIMES': 3,  # Thêm số lần thử lại khi thất bại\n",
    "        'LOG_LEVEL': 'INFO',  # Đặt mức log để theo dõi tiến trình\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        blocks = response.xpath(\"//div[contains(@class, 'uk-grid uk-grid-small uk-grid-width-1-1')]//div[contains(@class, 'item')]\")\n",
    "        for block in blocks:\n",
    "            link = block.xpath(\".//div[@class='name']/a/@href\").get()\n",
    "            if link:\n",
    "                link = response.urljoin(link)\n",
    "                yield scrapy.Request(url=link, callback=self.parse_details, errback=self.errback_httpbin, dont_filter=True)\n",
    "\n",
    "    def parse_details(self, response):\n",
    "        price = response.xpath(\"//strong[contains(@class, 'price')]/text()\").get()\n",
    "        if not price:\n",
    "            price = response.xpath(\"//strong[@class='price']/text()\").get()\n",
    "\n",
    "        params = response.xpath(\"//ul[contains(@class, 'uk-list')]//li\")\n",
    "        parameters = []\n",
    "        for param in params:\n",
    "            name = param.xpath(\"normalize-space(.//strong/text())\").get()\n",
    "            value = param.xpath(\"normalize-space(string())\").get()\n",
    "            if name and value:\n",
    "                parameters.append(f\"{name}: {value.replace(name, '').strip()}\")\n",
    "\n",
    "        # Extracting the specific \"Nội dung tin đăng\" content\n",
    "        details_section = response.xpath(\"//h3[contains(@class, 'uk-panel-title') and span/text()='Nội dung tin đăng']/following-sibling::div\")\n",
    "        details = details_section.xpath(\".//text()\").getall()\n",
    "        details = \" \".join(detail.strip() for detail in details if detail.strip())\n",
    "\n",
    "        yield {\n",
    "            'Link': response.url,\n",
    "            'Price': price.strip() if price else None,\n",
    "            'Parameters': \"\\n\".join(parameters),\n",
    "            'Details': details,\n",
    "        }\n",
    "\n",
    "    def errback_httpbin(self, failure):\n",
    "        # log all failures\n",
    "        self.logger.error(repr(failure))\n",
    "\n",
    "        if failure.check(HttpError):\n",
    "            # these are HTTP errors\n",
    "            response = failure.value.response\n",
    "            self.logger.error('HttpError on %s', response.url)\n",
    "\n",
    "        elif failure.check(DNSLookupError):\n",
    "            # this is the original request\n",
    "            request = failure.request\n",
    "            self.logger.error('DNSLookupError on %s', request.url)\n",
    "\n",
    "        elif failure.check(TimeoutError, TCPTimedOutError):\n",
    "            request = failure.request\n",
    "            self.logger.error('TimeoutError on %s', request.url)\n",
    "\n",
    "# Run the Spider\n",
    "process = CrawlerProcess(settings={\n",
    "    'FEED_FORMAT': 'json',\n",
    "    'FEED_URI': 'real_estate_data2.json',\n",
    "    'FEED_EXPORT_ENCODING': 'utf-8',\n",
    "    'DOWNLOAD_DELAY': 2,  # Thêm độ trễ giữa các yêu cầu\n",
    "    'RETRY_TIMES': 3,  # Thêm số lần thử lại khi thất bại\n",
    "    'LOG_ENABLED': True\n",
    "})\n",
    "\n",
    "process.crawl(RealEstateSpider)\n",
    "process.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cấu trúc và chức năng:\n",
    "  + RealEstateSpider là lớp spider chính, bắt đầu thu thập dữ liệu từ danh sách các trang chứa danh sách các căn hộ chung cư.\n",
    "  + parse là hàm đầu tiên xử lý từng trang, tìm kiếm các link chi tiết của từng căn hộ và gọi hàm parse_details để xử lý chi tiết từng căn hộ.\n",
    "  + parse_details là hàm xử lý các thông tin chi tiết của từng căn hộ như giá, các thông số và nội dung tin đăng.\n",
    "- Cấu hình:\n",
    "  + custom_settings được sử dụng để thiết lập các cấu hình cụ thể cho spider này như định dạng và đường dẫn file xuất, mã hóa, độ trễ tải xuống giữa các yêu cầu và số lần thử lại khi gặp lỗi.\n",
    "  + Các cấu hình này giúp tối ưu hóa hiệu suất và độ tin cậy của spider.\n",
    "- Xử lý lỗi:\n",
    "  + Hàm errback_httpbin được sử dụng để xử lý các lỗi xảy ra trong quá trình gửi yêu cầu HTTP, bao gồm các lỗi như HttpError, DNSLookupError, và TimeoutError.\n",
    "  + Điều này giúp đảm bảo rằng spider có thể tiếp tục chạy và ghi nhận lại các lỗi để có thể xử lý sau này.\n",
    "- Xuất dữ liệu:\n",
    "  + Dữ liệu thu thập được xuất ra file JSON với tên là real_estate_data2.json và được mã hóa UTF-8 để đảm bảo tính toàn vẹn của dữ liệu khi chứa các ký tự đặc biệt.\n",
    "- Log và giám sát:\n",
    "  + Mức độ log được đặt là INFO để giúp giám sát tiến trình của spider mà không gây quá tải với quá nhiều thông tin chi tiết.\n",
    "- Hiệu quả và tin cậy:\n",
    "  + Đoạn mã đã thêm độ trễ giữa các yêu cầu và thiết lập số lần thử lại để tăng cường độ tin cậy khi gặp các lỗi mạng hoặc server.\n",
    "Việc sử dụng dont_filter=True trong yêu cầu chi tiết giúp đảm bảo rằng tất cả các link được xử lý mà không bị bỏ qua do bộ lọc URL của Scrapy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ưu điểm\n",
    "  + Độ trễ giữa các yêu cầu: Giúp giảm tải cho máy chủ, tránh bị chặn.\n",
    "  + Thử lại khi thất bại: Tăng khả năng hoàn thành thu thập dữ liệu ngay cả khi gặp lỗi.\n",
    "  + Ghi log chi tiết: Giúp dễ dàng theo dõi tiến trình và xử lý sự cố.\n",
    "- Nhược điểm\n",
    "  + Tốc độ thu thập chậm: Do có độ trễ giữa các yêu cầu, tốc độ thu thập dữ liệu sẽ chậm hơn.\n",
    "  + Xử lý lỗi chưa toàn diện: Một số lỗi không được xử lý cụ thể có thể gây gián đoạn tiến trình.\n",
    "  + Phụ thuộc vào cấu trúc trang web: Nếu cấu trúc trang web thay đổi, mã sẽ không hoạt động chính xác và cần phải cập nhật lại."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
